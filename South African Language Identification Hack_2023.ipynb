{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "378fd8a0",
   "metadata": {},
   "source": [
    "# ExploreAI Academy Classification Hackathon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbd3338",
   "metadata": {},
   "source": [
    "## South African Language Identification Hack 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59748586",
   "metadata": {},
   "source": [
    "### EA language classification hackathon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12fa4ac",
   "metadata": {},
   "source": [
    "## Overview\n",
    "---\n",
    "South Africa is a multicultural society that is characterised by its rich linguistic diversity. Language is an indispensable tool that can be used to deepen democracy and also contribute to the social, cultural, intellectual, economic and political life of the South African society.\n",
    "\n",
    "The country is multilingual with 11 official languages, each of which is guaranteed equal status. Most South Africans are multilingual and able to speak at least two or more of the official languages. (From South African Government)\n",
    "\n",
    "With such a multilingual population, it is only obvious that our systems and devices also communicate in multi-languages.\n",
    "\n",
    "In this challenge, you will take text which is in any of South Africa's 11 Official languages and identify which language the text is in. This is an example of NLP's Language Identification, the task of determining the natural language that a piece of text is written in.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6390fbfd",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "53fab870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5614fb",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "677cd2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and test datasets\n",
    "train_data = pd.read_csv('train_set.csv')\n",
    "test_data = pd.read_csv('test_set.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbabaf0a",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c96661ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  lang_id                                               text\n",
      "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
      "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
      "2     eng  the province of kwazulu-natal department of tr...\n",
      "3     nso  o netefatša gore o ba file dilo ka moka tše le...\n",
      "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana...\n"
     ]
    }
   ],
   "source": [
    "#view train dataset\n",
    "print(train_data.head())  # View the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1b398b97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33000 entries, 0 to 32999\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   lang_id  33000 non-null  object\n",
      " 1   text     33000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 515.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Get information about the train dataset\n",
    "print(train_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fc743646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33000, 2)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of the train dataset\n",
    "print(train_data.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8ba620d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index                                               text\n",
      "0      1  Mmasepala, fa maemo a a kgethegileng a letlele...\n",
      "1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
      "2      3         Tshivhumbeo tshi fana na ngano dza vhathu.\n",
      "3      4  Kube inja nelikati betingevakala kutsi titsini...\n",
      "4      5                      Winste op buitelandse valuta.\n"
     ]
    }
   ],
   "source": [
    "#view test dataset\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bb804793",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5682 entries, 0 to 5681\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   index   5682 non-null   int64 \n",
      " 1   text    5682 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 88.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Get information about the test dataset\n",
    "print(test_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f1b8c43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5682, 2)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of the test dataset\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4471e4ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tsn</td>\n",
       "      <td>fa le dirisiwa lebone le tshwanetse go bontsha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nbl</td>\n",
       "      <td>lapho inarha yangeqadi ingenwe ngokungasimthet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>zul</td>\n",
       "      <td>i-tip-offs anonymous wusizo locingo oluzimele ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>nbl</td>\n",
       "      <td>isitifikhethi somtjhado esingakarhunyezwa namk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32980</th>\n",
       "      <td>ssw</td>\n",
       "      <td>inhloso ye-wua kutsi yente bantfu bendzawo let...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32983</th>\n",
       "      <td>ssw</td>\n",
       "      <td>timiso tesigatjana titawusebenta ngetingucuko ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32985</th>\n",
       "      <td>nso</td>\n",
       "      <td>ge o nyaka go kgopela phihlelelo ya direkoto t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32989</th>\n",
       "      <td>ssw</td>\n",
       "      <td>imenenja yesigodzi utakwatisa ngembhalo uma le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32996</th>\n",
       "      <td>sot</td>\n",
       "      <td>modise mosadi na o ntse o sa utlwe hore thaban...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5599 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lang_id                                               text\n",
       "0         xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "9         tsn  fa le dirisiwa lebone le tshwanetse go bontsha...\n",
       "10        nbl  lapho inarha yangeqadi ingenwe ngokungasimthet...\n",
       "12        zul  i-tip-offs anonymous wusizo locingo oluzimele ...\n",
       "19        nbl  isitifikhethi somtjhado esingakarhunyezwa namk...\n",
       "...       ...                                                ...\n",
       "32980     ssw  inhloso ye-wua kutsi yente bantfu bendzawo let...\n",
       "32983     ssw  timiso tesigatjana titawusebenta ngetingucuko ...\n",
       "32985     nso  ge o nyaka go kgopela phihlelelo ya direkoto t...\n",
       "32989     ssw  imenenja yesigodzi utakwatisa ngembhalo uma le...\n",
       "32996     sot  modise mosadi na o ntse o sa utlwe hore thaban...\n",
       "\n",
       "[5599 rows x 2 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking duplicates in train_data\n",
    "msg= train_data['text']\n",
    "train_data[msg.isin(msg[msg.duplicated()])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6ebfbae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xho    3000\n",
      "eng    3000\n",
      "nso    3000\n",
      "ven    3000\n",
      "tsn    3000\n",
      "nbl    3000\n",
      "zul    3000\n",
      "ssw    3000\n",
      "tso    3000\n",
      "sot    3000\n",
      "afr    3000\n",
      "Name: lang_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# EDA: Analyze the distribution of languages in the training dataset\n",
    "language_counts = train_data['lang_id'].value_counts()\n",
    "print(language_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcec2fad",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703fcd11",
   "metadata": {},
   "source": [
    "#### Data Processing: Convert text to lowercase and remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6fac2b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to preprocess the text\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = ''.join(char for char in text if char.isalpha() or char.isspace())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e63db24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the preprocessing function to the 'text' column in both datasets\n",
    "train_data['text'] = train_data['text'].apply(preprocess_text)\n",
    "test_data['text'] = test_data['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131e62cf",
   "metadata": {},
   "source": [
    "## Engineering Feastures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823c6a48",
   "metadata": {},
   "source": [
    "#### Feature Engineering: Extract additional features if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "dcf4b48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this case, we can add the text length as a feature\n",
    "train_data['text_length'] = train_data['text'].apply(len)\n",
    "test_data['text_length'] = test_data['text'].apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e76277a",
   "metadata": {},
   "source": [
    "#### Feature Extraction: Convert text data into numerical features using different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a976fd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag-of-Words representation\n",
    "vectorizer_bow = CountVectorizer()\n",
    "X_train_bow = vectorizer_bow.fit_transform(train_data['text'])\n",
    "X_test_bow = vectorizer_bow.transform(test_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "783e5f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF representation\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer_tfidf.fit_transform(train_data['text'])\n",
    "X_test_tfidf = vectorizer_tfidf.transform(test_data['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1e6e4366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target labels\n",
    "y_train = train_data['lang_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480e8228",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d976dd36",
   "metadata": {},
   "source": [
    "#### Model Training and Evaluation: Train different models and evaluate their performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4938a0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training data into training and validation sets\n",
    "X_train_bow_split, X_val_bow_split, y_train_split, y_val_split = train_test_split(X_train_bow, y_train, test_size=0.20, random_state=42)\n",
    "X_train_tfidf_split, X_val_tfidf_split, y_train_split, y_val_split = train_test_split(X_train_tfidf, y_train, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1a8b42dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: Multinomial Naive Bayes classifier with Bag-of-Words\n",
    "classifier_bow = MultinomialNB()\n",
    "classifier_bow.fit(X_train_bow_split, y_train_split)\n",
    "predictions_bow = classifier_bow.predict(X_val_bow_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5966fdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: Logistic Regression classifier with TF-IDF\n",
    "classifier_tfidf = LogisticRegression(max_iter=1000)\n",
    "classifier_tfidf.fit(X_train_tfidf_split, y_train_split)\n",
    "predictions_tfidf = classifier_tfidf.predict(X_val_tfidf_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b07fd926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: Stochastic Gradient Descent (SGD) classifier with Bag-of-Words\n",
    "classifier_sgd = SGDClassifier()\n",
    "param_grid_sgd = {\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'max_iter': [100, 200, 500]\n",
    "}\n",
    "grid_search_sgd = GridSearchCV(classifier_sgd, param_grid=param_grid_sgd, cv=5)\n",
    "grid_search_sgd.fit(X_train_bow_split, y_train_split)\n",
    "best_classifier_sgd = grid_search_sgd.best_estimator_\n",
    "predictions_sgd = best_classifier_sgd.predict(X_val_bow_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0a9b4814",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model 4: Linear Support Vector Classification (LinearSVC) with TF-IDF\n",
    "classifier_svc = LinearSVC()\n",
    "param_grid_svc = {\n",
    "    'C': [0.1, 1.0, 10.0],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'max_iter': [100, 200, 500]\n",
    "}\n",
    "grid_search_svc = GridSearchCV(classifier_svc, param_grid=param_grid_svc, cv=5)\n",
    "grid_search_svc.fit(X_train_tfidf_split, y_train_split)\n",
    "best_classifier_svc = grid_search_svc.best_estimator_\n",
    "predictions_svc = best_classifier_svc.predict(X_val_tfidf_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a9bdc4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Metrics\n",
    "accuracy_bow = accuracy_score(y_val_split, predictions_bow)\n",
    "precision_bow = precision_score(y_val_split, predictions_bow, average='weighted')\n",
    "recall_bow = recall_score(y_val_split, predictions_bow, average='weighted')\n",
    "f1_score_bow = f1_score(y_val_split, predictions_bow, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "88ef99d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_tfidf = accuracy_score(y_val_split, predictions_tfidf)\n",
    "precision_tfidf = precision_score(y_val_split, predictions_tfidf, average='weighted')\n",
    "recall_tfidf = recall_score(y_val_split, predictions_tfidf, average='weighted')\n",
    "f1_score_tfidf = f1_score(y_val_split, predictions_tfidf, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c22602d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_sgd = accuracy_score(y_val_split, predictions_sgd)\n",
    "precision_sgd = precision_score(y_val_split, predictions_sgd, average='weighted')\n",
    "recall_sgd = recall_score(y_val_split, predictions_sgd, average='weighted')\n",
    "f1_score_sgd = f1_score(y_val_split, predictions_sgd, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "67ec0a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_svc = accuracy_score(y_val_split, predictions_svc)\n",
    "precision_svc = precision_score(y_val_split, predictions_svc, average='weighted')\n",
    "recall_svc = recall_score(y_val_split, predictions_svc, average='weighted')\n",
    "f1_score_svc = f1_score(y_val_split, predictions_svc, average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ce897f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag-of-Words Model:\n",
      "Accuracy: 0.9989393939393939\n",
      "Precision: 0.998941955790228\n",
      "Recall: 0.9989393939393939\n",
      "F1 Score: 0.9989392771541917\n"
     ]
    }
   ],
   "source": [
    "print(\"Bag-of-Words Model:\")\n",
    "print(\"Accuracy:\", accuracy_bow)\n",
    "print(\"Precision:\", precision_bow)\n",
    "print(\"Recall:\", recall_bow)\n",
    "print(\"F1 Score:\", f1_score_bow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "733bfc01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Model:\n",
      "Accuracy: 0.9943939393939394\n",
      "Precision: 0.9944216933464599\n",
      "Recall: 0.9943939393939394\n",
      "F1 Score: 0.9943976987335509\n"
     ]
    }
   ],
   "source": [
    "print(\"TF-IDF Model:\")\n",
    "print(\"Accuracy:\", accuracy_tfidf)\n",
    "print(\"Precision:\", precision_tfidf)\n",
    "print(\"Recall:\", recall_tfidf)\n",
    "print(\"F1 Score:\", f1_score_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c11203d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Model:\n",
      "Accuracy: 0.9954545454545455\n",
      "Precision: 0.9954657211179962\n",
      "Recall: 0.9954545454545455\n",
      "F1 Score: 0.995458252459493\n"
     ]
    }
   ],
   "source": [
    "print(\"SGD Model:\")\n",
    "print(\"Accuracy:\", accuracy_sgd)\n",
    "print(\"Precision:\", precision_sgd)\n",
    "print(\"Recall:\", recall_sgd)\n",
    "print(\"F1 Score:\", f1_score_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e9e3fb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC Model:\n",
      "Accuracy: 0.9965151515151515\n",
      "Precision: 0.9965163927529209\n",
      "Recall: 0.9965151515151515\n",
      "F1 Score: 0.996513421406879\n"
     ]
    }
   ],
   "source": [
    "print(\"LinearSVC Model:\")\n",
    "print(\"Accuracy:\", accuracy_svc)\n",
    "print(\"Precision:\", precision_svc)\n",
    "print(\"Recall:\", recall_svc)\n",
    "print(\"F1 Score:\", f1_score_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "83183a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the best-performing model for final predictions\n",
    "best_model = classifier_bow\n",
    "best_predictions = predictions_bow\n",
    "best_model_name = 'Bag-of-Words Model'\n",
    "\n",
    "if accuracy_tfidf > accuracy_bow:\n",
    "    best_model = classifier_tfidf\n",
    "    best_predictions = predictions_tfidf\n",
    "    best_model_name = 'TF-IDF Model'\n",
    "\n",
    "if accuracy_sgd > accuracy_bow and accuracy_sgd > accuracy_tfidf:\n",
    "    best_model = classifier_sgd\n",
    "    best_predictions = predictions_sgd\n",
    "    best_model_name = 'SGD Model'\n",
    "\n",
    "if accuracy_svc > accuracy_bow and accuracy_svc > accuracy_tfidf and accuracy_svc > accuracy_sgd:\n",
    "    best_model = classifier_svc\n",
    "    best_predictions = predictions_svc\n",
    "    best_model_name = 'LinearSVC Model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b86c5877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final predictions\n",
    "final_predictions = best_model.predict(X_test_bow if best_model_name == 'Bag-of-Words Model' else X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a5dbe440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare submission file in CSV format\n",
    "submission_df = pd.DataFrame({'index': test_data['index'], 'lang_id': predictions})\n",
    "submission_df.to_csv('best_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "332dd7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare submission files for each model\n",
    "submission_bow = pd.DataFrame({'index': test_data['index'], 'lang_id': final_predictions})\n",
    "submission_bow.to_csv('submission_bow.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d3be892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_tfidf = pd.DataFrame({'index': test_data['index'], 'lang_id': final_predictions})\n",
    "submission_tfidf.to_csv('submission_tfidf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3ae9f2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_sgd = pd.DataFrame({'index': test_data['index'], 'lang_id': final_predictions})\n",
    "submission_sgd.to_csv('submission_sgd.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ceba9f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_svc = pd.DataFrame({'index': test_data['index'], 'lang_id': final_predictions})\n",
    "submission_svc.to_csv('submission_svc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "1e88771d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission files created successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"Submission files created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ccd40e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
